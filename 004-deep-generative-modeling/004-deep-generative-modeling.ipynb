{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e394a4a-2da7-45b2-8760-4c8f97d1e326",
   "metadata": {},
   "source": [
    "# Deep Generative Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab07860-2f5b-4c7d-a3c1-eaf79baa1f83",
   "metadata": {},
   "source": [
    "## Supervised Learning\n",
    "\n",
    "**Data:$(x, y)$**,\n",
    "$x$ is data, $y$ is label\n",
    "\n",
    "**Goal:** Learn function to map $x \\rightarrow y$\n",
    "\n",
    "**Examples:** Classification, regression, object detection, semantic segmentation, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f614b3be-00a1-4ced-bb32-42ce7e1cba60",
   "metadata": {},
   "source": [
    "## Unsupervised Learning\n",
    "\n",
    "**Data: $x$**,\n",
    "$x$ is data, no labels!\n",
    "\n",
    "**Goal:** Learn the hidden or underlying structure of the data\n",
    "\n",
    "**Examples:** Clustering, feature or dimensionality reduction, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854933c2-79ef-4044-9072-62ecf90731ef",
   "metadata": {},
   "source": [
    "## Generative Modeling\n",
    "\n",
    "**Goal:** Take as input training samples from some distribution and learn a model that represents that distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55568719-e23f-4c31-96e9-d6f2c6f9ce9d",
   "metadata": {},
   "source": [
    "## Autoencoders: Background\n",
    "\n",
    "Unsupervised approach for learning a **lower-dimensional** feature representation from unlabeled training data. \"Decoder\" learns mapping back from latent space $Z$, to reconstructed observation $\\hat{x}$\n",
    "\n",
    "<center><img src=\"./assets/autoencoder.svg\"></center>\n",
    "\n",
    "**Bottleneck hidden layer** forces network to learn a compressed latent representation\n",
    "\n",
    "**Reconstruction loss** force the latent representation to capture (or encode) as much \"information\" about the data as posible\n",
    "\n",
    "**Autoencoding** = **Auto**matically **encoding** data\n",
    "\n",
    "<center><img src=\"./assets/simple-representation-encoder.svg\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7eaa186-ec15-40ca-bf32-52168f29d57a",
   "metadata": {},
   "source": [
    "## Variational Autoencoders\n",
    "\n",
    "Variational autoencoders are a probabilistic twist on autoencoders, sample from the mean and standard deviation to compute latent sample.\n",
    "\n",
    "<center><img src=\"./assets/vae.svg\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788ac94a-e525-421b-92da-dc0d9517b996",
   "metadata": {},
   "source": [
    "## VAE Optimization\n",
    "\n",
    "<center><img src=\"./assets/vae-optimization.svg\"></center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
